{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve Tiny ImageNet image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 25% (50% points)\n",
    "    * 30% (60% points)\n",
    "    * 32.5% (70% points)\n",
    "    * 35% (80% points)\n",
    "    * 37.5% (90% points)\n",
    "    * 40% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 40%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the anytask atttachments). After that, you can use whatever you want.\n",
    "* you __can't__ do anything with validation data apart from running the evaluation procedure. Please, split train images on train and validation parts\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, define data loader and neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys # define path for data loader\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload # reload modules before executing each line\n",
    "%autoreload 2\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's have a cell with global hyperparameters for the CNNs in this notebook\n",
    "\n",
    "# Path to a directory with image dataset and subfolders for training, validation and final testing\n",
    "DATA_PATH = r\"../data/TinyImagenet\" # PATH TO THE DATASET\n",
    "\n",
    "# Number of threads for data loader\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Image size: even though image sizes are bigger than 96, we use this to speed up training\n",
    "SIZE_H = SIZE_W = 96\n",
    "\n",
    "# Number of classes in the dataset\n",
    "NUM_CLASSES = 200\n",
    "\n",
    "# Epochs: number of passes over the training data, we use it this small to reduce training babysitting time\n",
    "EPOCH_NUM = 30\n",
    "\n",
    "# Batch size: for batch gradient descent optimization, usually selected as 2**K elements\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Images mean and std channelwise\n",
    "image_mean = [0.4803, 0.4480, 0.3976] # ImageNet: [0.485, 0.456, 0.406]\n",
    "image_std  = [0.229, 0.224, 0.225] # ImageNet: [0.229, 0.224, 0.225])\n",
    "\n",
    "# Last layer (embeddings) size for CNN models\n",
    "EMBEDDING_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you're running in colab,\n",
    "# 1. go to Runtime -> Change Runtimy Type -> GPU\n",
    "# 2. uncomment this:\n",
    "# !wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py -O tiny_img.py\n",
    "# data_path = '.'\n",
    "# 3. comment this\n",
    "sys.path.insert(0, DATA_PATH)\n",
    "\n",
    "from tiny_img import download_tinyImg200\n",
    "# download_tinyImg200(DATA_PATH)\n",
    "# Use 100k examples for training and validation (and testing). There is also 10k images in tiny-imagenet-200/test folder.\n",
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transforms.ToTensor())\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [90000, 10000])\n",
    "# test_dataset, val_dataset = torch.utils.data.random_split(val_dataset, [10000, 10000])\n",
    "test_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/test', transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=BATCH_SIZE, \n",
    "                                              shuffle=True, \n",
    "                                              num_workers=NUM_WORKERS)\n",
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=BATCH_SIZE, \n",
    "                                            shuffle=True, \n",
    "                                            num_workers=NUM_WORKERS)\n",
    "\n",
    "test_batch_gen = torch.utils.data.DataLoader(test_dataset, \n",
    "                                             batch_size=BATCH_SIZE, \n",
    "                                             shuffle=True, \n",
    "                                             num_workers=NUM_WORKERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count mean for each channel. Assume t.shape == (channels, h, w)\n",
    "image_means = torch.stack([torch.mean(t, (1,2)) for t, c in train_dataset])\n",
    "image_means = torch.mean(image_means, 0)\n",
    "# torch.stack([print(t.shape) for t, c in train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(image_means, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count std for each channel. Assume t.shape == (channels, h, w)\n",
    "# image_std = torch.stack([t.var(1).var(1) for t, c in train_dataset])\n",
    "torch.var(image_std,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\" Docstring\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Downloads/deep-learning/YDS/<ipython-input-83-7089779f452b>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-6ac8c4679cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Get a batch of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Make a grid from batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "def plot_from_batch_generator(batch_gen, grid_size=(3,3)):\n",
    "    \"\"\"Plots :grid_size: images from :batch_gen: \"\"\"\n",
    "    data_batch, label_batch = next(iter(batch_gen))\n",
    "    grid_size = (3, 3)\n",
    "    f, axarr = plt.subplots(*grid_size)\n",
    "    f.set_size_inches(15,10)\n",
    "    class_names = batch_gen.dataset.classes\n",
    "    for i in range(grid_size[0] * grid_size[1]):\n",
    "        \n",
    "        # read images from batch to numpy.ndarray and change axes order [H, W, C] -> [H, W, C]\n",
    "        batch_image_ndarray = np.transpose(data_batch[i].numpy(), [1, 2, 0])\n",
    "        \n",
    "        # inverse normalization for image data values back to [0,1] and clipping the values for correct pyplot.imshow()\n",
    "        src = np.clip(image_std * batch_image_ndarray + image_mean, 0, 1)\n",
    "        \n",
    "        # display batch samples with labels\n",
    "        sample_title = 'Label = %d (%s)' % (label_batch[i], class_names[label_batch[i]])\n",
    "        axarr[i // grid_size[0], i % grid_size[0]].imshow(src)\n",
    "        axarr[i // grid_size[0], i % grid_size[0]].set_title(sample_title)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "def compute_loss(X_batch, y_batch):\n",
    "    \"\"\" Docstring\"\"\"\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
    "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
    "    logits = model.cuda()(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []\n",
    "\n",
    "num_epochs = 50 # total amount of full passes over training data\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in train_batch_gen:\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    \n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in val_batch_gen:\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "        y_pred = logits.max(1)[1].data\n",
    "        val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in val_batch_gen:\n",
    "    logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
    "    y_pred = logits.max(1)[1].data\n",
    "    test_batch_acc.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 70:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 20:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is done, please calculate accuracy on `tiny-imagenet-200/val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = .... # YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 35:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 25:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `___ ___`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "* brief text on what was\n",
    "* the original idea\n",
    "* and why it was so\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "* Some explaination about what were the results,\n",
    "* what worked and what didn't\n",
    "* most importantly - what next steps were taken, if any\n",
    "* and what were their respective outcomes\n",
    "\n",
    "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n",
    "\n",
    "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
    "\n",
    "* accuracy on training: __\n",
    "* accuracy on validation: __\n",
    "* accuracy on test: __\n",
    "\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-kernel",
   "language": "python",
   "name": "dl-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
